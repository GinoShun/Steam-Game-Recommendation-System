{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def focal_loss(alpha=0.13, gamma=2):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        loss = -alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1) \\\n",
    "               - (1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0)\n",
    "        return K.mean(loss)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num = np.load('../data/test/numerical/X_test_scaled.npy')\n",
    "y_test_num = np.load('../data/test/numerical/y_test.npy')\n",
    "resnet_model = tf.keras.models.load_model('../model/resnet_baseline2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_predictions = resnet_model.predict(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions\n",
    "np.save('../data/test/numerical/resnet_predictions.npy', resnet_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy\n",
    "accuracy = accuracy_score(y_test_num, resnet_predictions.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.load_model('../model/best_lstm_model.h5')\n",
    "X_test_seq = np.load('../data/test/timeSeries/X_test.npy')\n",
    "y_test_seq = np.load('../data/test/timeSeries/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105940/105940 [==============================] - 334s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_predictions = lstm_model.predict(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "np.save('../data/test/timeSeries/lstm_predictions.npy', lstm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8946328231077303\n"
     ]
    }
   ],
   "source": [
    "# check accuracy\n",
    "accuracy = accuracy_score(y_test_seq, np.round(lstm_predictions))\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = np.load('../data/test/timeSeries/lstm_predictions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.18      0.28    395462\n",
      "           1       0.90      0.99      0.94   2994607\n",
      "\n",
      "    accuracy                           0.89   3390069\n",
      "   macro avg       0.79      0.58      0.61   3390069\n",
      "weighted avg       0.88      0.89      0.87   3390069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check precision, recall, f1-score\n",
    "print(classification_report(y_test_seq, np.round(lstm_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'focal_loss_fixed': focal_loss()}\n",
    "\n",
    "ncf_model = tf.keras.models.load_model('../model/best_ncf_model.h5', custom_objects=custom_objects)\n",
    "X_test_user_ncf = np.load('../data/test/ncf/realworld/X_test_user_encoded.npy')\n",
    "X_test_item_ncf = np.load('../data/test/ncf/realworld/X_test_item_encoded.npy')\n",
    "X_test_features_ncf = np.load('../data/test/ncf/realworld/X_test_features.npy')\n",
    "y_test_ncf = np.load('../data/test/ncf/realworld/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105940/105940 [==============================] - 46s 431us/step\n"
     ]
    }
   ],
   "source": [
    "ncf_predictions = ncf_model.predict([X_test_user_ncf, X_test_item_ncf, X_test_features_ncf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "np.save('../data/test/ncf/realworld/ncf_predictions.npy', ncf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8832811367556236\n"
     ]
    }
   ],
   "source": [
    "# check accuracy\n",
    "accuracy = accuracy_score(y_test_ncf, np.round(ncf_predictions))\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yulindong/miniforge3/envs/CV/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yulindong/miniforge3/envs/CV/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    395685\n",
      "           1       0.88      1.00      0.94   2994384\n",
      "\n",
      "    accuracy                           0.88   3390069\n",
      "   macro avg       0.44      0.50      0.47   3390069\n",
      "weighted avg       0.78      0.88      0.83   3390069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yulindong/miniforge3/envs/CV/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# check precision, recall, f1-score\n",
    "print(classification_report(y_test_ncf, np.round(ncf_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, predictions, model_name):\n",
    "    \"\"\"\n",
    "    draw the ROC curve\n",
    "    for single model\n",
    "    \"\"\"\n",
    "    # calculate fpr, tpr\n",
    "    fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "    \n",
    "    # calculate AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # plot the ROC curve\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "def plot_all_models_roc(y_test_num, y_test_seq, y_test_ncf, \n",
    "                        resnet_predictions, lstm_predictions, ncf_predictions):\n",
    "    \"\"\"\n",
    "    plot the ROC curve for all three models\n",
    "    \n",
    "    features:\n",
    "    y_test_num, y_test_seq, y_test_ncf: test labels for three models\n",
    "    resnet_predictions, lstm_predictions, ncf_predictions: predictions for three models\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    \n",
    "    # 绘制 ResNet 模型的 ROC 曲线\n",
    "    plot_roc_curve(y_test_num, resnet_predictions, 'ResNet Model')\n",
    "    \n",
    "    # 绘制 LSTM 模型的 ROC 曲线\n",
    "    plot_roc_curve(y_test_seq, lstm_predictions, 'LSTM Model')\n",
    "    \n",
    "    # 绘制 NCF 模型的 ROC 曲线\n",
    "    plot_roc_curve(y_test_ncf, ncf_predictions, 'NCF Model')\n",
    "    \n",
    "    # 绘制对角线参考线\n",
    "    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')\n",
    "    \n",
    "    # 设置图的范围和标签\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    \n",
    "    # 显示图例\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # 显示图\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数绘制三种模型的 ROC 曲线\n",
    "plot_all_models_roc(y_test_num, y_test_seq, y_test_ncf, \n",
    "                    resnet_predictions, lstm_predictions, ncf_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
